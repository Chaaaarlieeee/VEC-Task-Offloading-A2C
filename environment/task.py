"""
Task Management Module
Defines task class, task status, priority and task generator
"""

import numpy as np
from enum import Enum


class TaskPriority(Enum):
    """Task priority enumeration"""
    LOW = 0
    HIGH = 1


class TaskStatus(Enum):
    """Task status enumeration"""
    WAITING = 0              # Waiting for assignment
    QUEUED = 1               # In queue waiting for processing
    PROCESSING = 2           # Being processed
    COMPLETED = 3            # Completed
    FAILED_OVERTIME = 4      # Failed (exceeded deadline)
    FAILED_NO_CACHE = 5      # Failed (no cache resource)
    FAILED_OUT_OF_RSU = 6    # Failed (out of RSU coverage)
    FAILED_NO_ALLOCATION = 7 # Failed (skipped task assignment)
    TRANSMITTING = 8         # Task transmitting
    FAILED_RSU_FAILURE = 9   # Failed (RSU failure)
    FAILED_QUEUE_OVERFLOW = 10  # Failed (transmission queue overflow)


class Task:
    """
    Task Object Class
    Represents a computation task generated by a vehicle
    """
    
    def __init__(self, task_id, size, complexity, priority, deadline):
        """
        Initialize task object
        
        Args:
            task_id (int): Task unique identifier
            size (float): Task data size in bytes, range from 300KB to 10MB
            complexity (float): Computation complexity in CPU cycles/bit, range 200-500
            priority (TaskPriority): Task priority, LOW or HIGH
            deadline (float): Deadline in seconds, range from 0.1s to 10s
        """
        # Basic parameters
        self.id = task_id
        self.size = size                      # Task size (bytes)
        self.complexity = complexity          # Computation complexity (CPU cycles per bit)
        self.priority = priority              # Priority (HIGH/LOW)
        self.deadline = deadline              # Deadline (seconds)
        self.creation_time = 0                # Task creation time
        self.current_process = self.complexity * self.size * 8  # Remaining computation needed
        
        # Status tracking
        self.status = TaskStatus.WAITING      # Task status
        self.progress = 0.0                   # Processing progress (0-1)
        self.location = -1                    # Processing location: -1(unassigned), 0(local), 1+(RSU index)
        self.queue_position = -1              # Queue position
        self.allocated_computing_power = None # Allocated computing resource (GHz)
        
        # Time tracking
        self.assignment_time = None           # Task assignment time
        self.transmission_start_time = None   # Transmission start time
        self.transmission_end_time = None     # Transmission end time
        self.processing_start_time = None     # Processing start time
        self.completion_time = None           # Task completion time
        
        # Performance metrics
        self.transmission_time = None         # Transmission duration
        self.waiting_time = None              # Waiting duration
        self.processing_time = None           # Processing duration
        self.total_time = None                # Total duration
        self.success = None                   # Whether task completed successfully
        
        # Transmission progress tracking
        self.transmitted_data = 0             # Transmitted data (bytes)
    
    def assign(self, location, current_time):
        """Assign task to specified location"""
        self.location = location
        self.status = TaskStatus.QUEUED
        self.assignment_time = current_time
    
    def start_transmission(self, current_time):
        """Start task transmission"""
        self.status = TaskStatus.TRANSMITTING
        self.transmission_start_time = current_time
        self.transmitted_data = 0
    
    def end_transmission(self, current_time):
        """End task transmission"""
        self.status = TaskStatus.QUEUED
        self.transmission_end_time = current_time
        self.transmission_time = self.transmission_end_time - self.transmission_start_time
        self.transmitted_data = self.size
    
    def update_transmission(self, transmitted_bytes):
        """Update transmitted data amount"""
        self.transmitted_data += transmitted_bytes
        self.transmitted_data = min(self.transmitted_data, self.size)
    
    def get_remaining_data(self):
        """Get remaining data to transmit"""
        return max(0, self.size - self.transmitted_data)
    
    def start_processing(self, current_time):
        """Start processing task"""
        self.status = TaskStatus.PROCESSING
        self.processing_start_time = current_time
    
    def update_progress(self, progress_delta):
        """Update task processing progress"""
        self.progress += progress_delta
        if self.progress >= 1.0:
            self.progress = 1.0
    
    def complete(self, current_time):
        """Mark task as completed"""
        self.status = TaskStatus.COMPLETED
        self.completion_time = current_time
        self.processing_time = self.completion_time - self.processing_start_time
        
        if self.transmission_time is not None:
            self.waiting_time = self.processing_start_time - self.transmission_end_time
        else:
            self.waiting_time = self.processing_start_time - self.assignment_time
        
        self.total_time = self.completion_time - self.creation_time
        self.success = self.completion_time <= (self.creation_time + self.deadline)
        self.allocated_computing_power = None
    
    def fail_overtime(self, current_time):
        """Mark task as failed due to overtime"""
        self.status = TaskStatus.FAILED_OVERTIME
        self.completion_time = current_time
        self.total_time = self.completion_time - self.creation_time
        self.success = False
        self.allocated_computing_power = None
    
    def fail_no_cache(self, current_time):
        """Mark task as failed due to insufficient cache"""
        self.status = TaskStatus.FAILED_NO_CACHE
        self.completion_time = current_time
        self.total_time = self.completion_time - self.creation_time
        self.success = False
        self.allocated_computing_power = None
    
    def fail_out_of_rsu(self, current_time):
        """Mark task as failed due to out of RSU coverage"""
        self.status = TaskStatus.FAILED_OUT_OF_RSU
        self.completion_time = current_time
        self.total_time = self.completion_time - self.creation_time
        self.success = False
        self.allocated_computing_power = None
    
    def fail_no_allocation(self, current_time):
        """Mark task as failed due to skipped allocation"""
        self.status = TaskStatus.FAILED_NO_ALLOCATION
        self.completion_time = current_time
        self.total_time = self.completion_time - self.creation_time
        self.success = False
        self.allocated_computing_power = None
    
    def fail_rsu_failure(self, current_time):
        """Mark task as failed due to RSU failure"""
        self.status = TaskStatus.FAILED_RSU_FAILURE
        self.completion_time = current_time
        self.total_time = self.completion_time - self.creation_time
        self.success = False
        self.allocated_computing_power = None
    
    def fail_queue_overflow(self, current_time):
        """Mark task as failed due to transmission queue overflow"""
        self.status = TaskStatus.FAILED_QUEUE_OVERFLOW
        self.completion_time = current_time
        self.total_time = self.completion_time - self.creation_time
        self.success = False
        self.allocated_computing_power = None
    
    def is_local(self):
        """Check if task is processed locally"""
        return self.location == 0
    
    def is_offloaded(self):
        """Check if task is offloaded to RSU"""
        return self.location > 0
    
    def get_remaining_work(self):
        """Get task's remaining computation workload"""
        return self.current_process
    
    def get_total_cycles(self):
        """Get task's total computation cycles"""
        return self.complexity * self.size * 8
    
    def time_to_deadline(self, current_time):
        """Get remaining time to deadline"""
        deadline_time = self.creation_time + self.deadline
        return deadline_time - current_time
    
    def is_overdue(self, current_time):
        """Check if task has exceeded deadline"""
        return current_time > (self.creation_time + self.deadline)
    
    def __str__(self):
        """String representation of task"""
        status_str = self.status.name
        location_str = "Unassigned" if self.location == -1 else ("Local" if self.location == 0 else f"RSU-{self.location}")
        
        result = (
            f"Task ID: {self.id}, Size: {self.size/1024:.2f}KB, "
            f"Complexity: {self.complexity:.1f} cycles/bit, Priority: {self.priority.name}, "
            f"Deadline: {self.deadline:.2f}s\n"
            f"Status: {status_str}, Location: {location_str}, Progress: {self.progress*100:.1f}%"
        )
        
        if self.completion_time is not None:
            success_str = "Success" if self.success else "Failed"
            result += f"\nResult: {success_str}, Total time: {self.total_time:.3f}s"
        
        return result


class TaskPoolGenerator:
    """
    Task Pool Generator
    Used for generating and managing task pool
    """
    
    def __init__(self, seed=None):
        """
        Initialize task pool generator
        
        Args:
            seed (int, optional): Random generator seed for reproducibility
        """
        self.random_state = np.random.RandomState(seed)
        self.task_counter = 0
        self.task_pool = []
        self.prob = 0.3  # Large task probability
    
    def generate_task(self):
        """
        Generate a single task
        
        Returns:
            Task: Newly generated task object
        """
        self.task_counter += 1
        
        # Randomly generate task parameters
        if self.random_state.rand() > self.prob:
            # Small task: 300KB-500KB
            size = self.random_state.uniform(300 * 1024, 500 * 1024)
            complexity = self.random_state.randint(50, 100)
            deadline = self.random_state.uniform(0.1, 0.5)
        else:
            # Large task: 1MB-3MB
            size = self.random_state.uniform(1 * 1024 * 1024, 3 * 1024 * 1024)
            complexity = self.random_state.randint(200, 500)
            deadline = self.random_state.uniform(5.0, 10.0)
        
        # Use 80/20 rule: 80% low priority, 20% high priority
        priority = TaskPriority.HIGH if self.random_state.random() < 0.2 else TaskPriority.LOW
        
        # Create new task
        task = Task(self.task_counter, size, complexity, priority, deadline)
        
        return task
    
    def generate_task_pool(self, num_tasks, save_to_file=None):

        new_tasks = []
        
        for _ in range(num_tasks):
            task = self.generate_task()
            new_tasks.append(task)
            self.task_pool.append(task)
        
        if save_to_file:
            self.save_task_pool(save_to_file)
        
        return new_tasks
    
    def save_task_pool(self, filename):
        """Save task pool to file"""
        import pickle
        with open(filename, 'wb') as f:
            pickle.dump(self.task_pool, f)
    
    def load_task_pool(self, filename):
        """Load task pool from file"""
        import pickle
        with open(filename, 'rb') as f:
            self.task_pool = pickle.load(f)
        
        if self.task_pool:
            self.task_counter = max(task.id for task in self.task_pool)
        
        return self.task_pool
    
    def get_task(self, current_time, index=None):
        """
        Get a copy of a task from the task pool
        
        Args:
            current_time (float): Current time
            index (int, optional): Task index to retrieve
            
        Returns:
            Task: Copy of the retrieved task object
        """
        import copy
        
        if not self.task_pool:
            return None
        
        if index is None:
            index = self.random_state.randint(0, len(self.task_pool))
        
        if 0 <= index < len(self.task_pool):
            task_copy = copy.deepcopy(self.task_pool[index])
            task_copy.creation_time = current_time
            return task_copy
        else:
            return None
    
    def clear_pool(self):
        """Clear task pool"""
        self.task_pool = []
    
    def get_pool_size(self):
        """Get task pool size"""
        return len(self.task_pool)
    
    def get_task_statistics(self):
        """Get task pool statistics"""
        if not self.task_pool:
            return {"count": 0}
        
        sizes = [task.size for task in self.task_pool]
        complexities = [task.complexity for task in self.task_pool]
        priorities = [task.priority.value for task in self.task_pool]
        deadlines = [task.deadline for task in self.task_pool]
        
        stats = {
            "count": len(self.task_pool),
            "size": {
                "min": min(sizes),
                "max": max(sizes),
                "mean": np.mean(sizes),
                "median": np.median(sizes)
            },
            "complexity": {
                "min": min(complexities),
                "max": max(complexities),
                "mean": np.mean(complexities),
                "median": np.median(complexities)
            },
            "priority": {
                "high_percentage": sum(p == TaskPriority.HIGH.value for p in priorities) / len(priorities) * 100,
                "low_percentage": sum(p == TaskPriority.LOW.value for p in priorities) / len(priorities) * 100
            },
            "deadline": {
                "min": min(deadlines),
                "max": max(deadlines),
                "mean": np.mean(deadlines),
                "median": np.median(deadlines)
            }
        }
        
        return stats

